#!/usr/bin/env python3

import copy
import itertools
import os
import socket
import time
import zlib
from functools import partial
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import joblib
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchio as tio
from sklearn.metrics import (accuracy_score, average_precision_score, balanced_accuracy_score,
                             log_loss, recall_score, roc_auc_score)
from sklearn.preprocessing import label_binarize


def makedir(path):
    if not os.path.exists(path):
        os.makedirs(path)


def find_high_activation_crop(activation_map, percentile=95):
    threshold = np.percentile(activation_map, percentile)
    mask = np.ones(activation_map.shape)
    mask[activation_map < threshold] = 0
    lower_y, upper_y, lower_x, upper_x = 0, 0, 0, 0
    for i in range(mask.shape[0]):
        if np.amax(mask[i]) > 0.5:
            lower_y = i
            break
    for i in reversed(range(mask.shape[0])):
        if np.amax(mask[i]) > 0.5:
            upper_y = i
            break
    for j in range(mask.shape[1]):
        if np.amax(mask[:, j]) > 0.5:
            lower_x = j
            break
    for j in reversed(range(mask.shape[1])):
        if np.amax(mask[:, j]) > 0.5:
            upper_x = j
            break
    return lower_y, upper_y + 1, lower_x, upper_x + 1


def get_hashes(args):
    args_ignored = ['model_name', 'v_mod', 'n_workers', 'n_threads', 'preloaded', 'gpus',
                    'load_model', 'save_model']
    opts = {k: v for k, v in vars(args).items() if k not in args_ignored}
    opts_hash = f"{zlib.crc32(str(opts).encode()):x}"
    return opts_hash


def load_data(data_path='../data/BraTS_2020/MICCAI_BraTS2020_TrainingData'):
    name_mapping = np.genfromtxt(f'{data_path}/name_mapping.csv', delimiter=',', dtype=None,
                                 encoding='utf8')
    subj_ids, labels = name_mapping[1:, -1], name_mapping[1:, 0]
    labels = label_binarize(np.array(labels == 'HGG', dtype=int), classes=[0, 1, np.inf])[:, :-1]
    subjs = []
    for subj_id, label in zip(subj_ids, labels):
        subj = tio.Subject(t1=tio.ScalarImage(f'{data_path}/{subj_id}/{subj_id}_t1.nii.gz'),
                           t1ce=tio.ScalarImage(f'{data_path}/{subj_id}/{subj_id}_t1ce.nii.gz'),
                           t2=tio.ScalarImage(f'{data_path}/{subj_id}/{subj_id}_t2.nii.gz'),
                           flair=tio.ScalarImage(f'{data_path}/{subj_id}/{subj_id}_flair.nii.gz'),
                           seg=tio.LabelMap(f'{data_path}/{subj_id}/{subj_id}_seg.nii.gz'),
                           subj_id=subj_id, label=label)
        subjs.append(subj)
    return np.array(subjs), labels


def load_subjs_batch(subjs_batch):
    if isinstance(subjs_batch, list):
        return subjs_batch
    else:
        data = torch.cat((subjs_batch['t1']['data'], subjs_batch['t1ce']['data'],
                          subjs_batch['t2']['data'], subjs_batch['flair']['data']), dim=1)
        return data, subjs_batch['label'], subjs_batch['seg']['data']


def preload(data_loader):
    x, y, seg = [], [], []
    percent = 10
    print("Preloading Dataset:")
    for b, subjs_batch in enumerate(data_loader):
        data, target, seg_map = load_subjs_batch(subjs_batch)
        x.append(data), y.append(target), seg.append(seg_map)
        while (b + 1) / len(data_loader) >= percent / 100:
            print(f"---{percent}%", end='', flush=True)
            percent += 10
    x, y, seg = torch.cat(x), torch.cat(y), torch.cat(seg)
    print(" Finished.")
    return x, y, seg


def get_batch_images_and_size(batch: Dict) -> Tuple[int, List[str], List[str]]:
    """Get batch size and lists of image names and other names in a batch.

    Args:
        batch: Dictionary generated by a :class:`torch.utils.data.DataLoader`
        extracting data from a :class:`torchio.SubjectsDataset`.

    Raises:
        RuntimeError: If the batch does not seem to contain any dictionaries
        that seem to represent a :class:`torchio.Image`.
    """
    batch_size, image_names, other_names = 0, [], []
    for key, value in batch.items():
        if isinstance(value, dict) and tio.constants.DATA in value:
            if batch_size > 0:
                assert batch_size == len(value[tio.constants.DATA]), 'The batch size is not unique'
            else:
                batch_size = len(value[tio.constants.DATA])
            image_names.append(key)
        else:
            if batch_size > 0:
                assert batch_size == len(value), 'The batch size is not unique'
            else:
                batch_size = len(value)
            other_names.append(key)
    if not image_names:
        raise RuntimeError('The batch does not seem to contain any images')
    return batch_size, image_names, other_names


def get_subjects_from_batch(batch: Dict) -> List:
    """Get list of subjects from collated batch.

    Args:
        batch: Dictionary generated by a :class:`torch.utils.data.DataLoader`
        extracting data from a :class:`torchio.SubjectsDataset`.
    """
    subjects = []
    batch_size, image_names, other_names = get_batch_images_and_size(batch)
    for i in range(batch_size):
        subject_dict = {}
        for image_name in image_names:
            image_dict = batch[image_name]
            data = image_dict[tio.constants.DATA][i]
            affine = image_dict[tio.constants.AFFINE][i]
            path = Path(image_dict[tio.constants.PATH][i])
            is_label = image_dict[tio.constants.TYPE][i] == tio.constants.LABEL
            klass = tio.LabelMap if is_label else tio.ScalarImage
            image = klass(tensor=data, affine=affine, filename=path.name)
            subject_dict[image_name] = image
        for other_name in other_names:
            subject_dict[other_name] = batch[other_name][i]
        subject = tio.Subject(subject_dict)
        if tio.constants.HISTORY in batch:
            applied_transforms = batch[tio.constants.HISTORY][i]
            for transform in applied_transforms:
                transform.add_transform_to_subject_history(subject)
        subjects.append(copy.deepcopy(subject))
    return subjects


def preprocess(data_loader):
    x = []
    percent = 10
    print("Preprocessing Dataset:")
    for b, subjs_batch in enumerate(data_loader):
        x += get_subjects_from_batch(subjs_batch)
        while (b + 1) / len(data_loader) >= percent / 100:
            print(f"---{percent}%", end='', flush=True)
            percent += 10
    print(" Finished.")
    return np.array(x)


def augment_brightness(t, multiplier_range=(0.5, 2)):
    multiplier = torch.empty(1).uniform_(multiplier_range[0], multiplier_range[1])
    return t * multiplier


def augment_contrast(t, contrast_range=(0.75, 1.25), preserve_range=True):
    if torch.rand(1) < 0.5 and contrast_range[0] < 1:
        factor = torch.empty(1).uniform_(contrast_range[0], 1)
    else:
        factor = torch.empty(1).uniform_(max(contrast_range[0], 1), contrast_range[1])
    t_mean = t.mean()
    if preserve_range:
        return ((t - t_mean) * factor + t_mean).clamp(t.min(), t.max())
    else:
        return (t - t_mean) * factor + t_mean


def augment_gamma(t, gamma_range=(0.5, 2), invert_image=False, epsilon=1e-12, retain_stats=True):
    if invert_image:
        t = -t
    if retain_stats:
        t_mean, t_std = t.mean(), t.std()
    if torch.rand(1) < 0.5 and gamma_range[0] < 1:
        gamma = torch.empty(1).uniform_(gamma_range[0], 1)
    else:
        gamma = torch.empty(1).uniform_(max(gamma_range[0], 1), gamma_range[1])
    t_min = t.min()
    t_range = (t.max() - t_min).clamp_min(epsilon)
    t = ((t - t_min) / t_range) ** gamma * t_range + t_min
    if retain_stats:
        t = (t - t.mean()) / t.std().clamp_min(epsilon) * t_std + t_mean
    if invert_image:
        t = -t
    return t


transform_augs: dict = {
    'af0': tio.OneOf(
        {
            tio.RandomAffine(scales=(0.7, 1.4), degrees=(0, 0), isotropic=True,
                             default_pad_value='otsu', exclude=['seg']): 0.16,
            tio.RandomAffine(scales=(1, 1), degrees=(-30, 30), isotropic=True,
                             default_pad_value='otsu', exclude=['seg']): 0.16,
            tio.RandomAffine(scales=(0.7, 1.4), degrees=(-30, 30), isotropic=True,
                             default_pad_value='otsu', exclude=['seg']): 0.04,
        },
        p=0.36,
    ),
    'af1': tio.OneOf(
        {
            tio.RandomAffine(scales=(0.7, 1.4), degrees=(0, 0), isotropic=True,
                             default_pad_value='otsu', exclude=['seg']): 0.25,
            tio.RandomAffine(scales=(1, 1), degrees=(-30, 30), isotropic=True,
                             default_pad_value='otsu', exclude=['seg']): 0.25,
            tio.RandomAffine(scales=(0.7, 1.4), degrees=(-30, 30), isotropic=True,
                             default_pad_value='otsu', exclude=['seg']): 0.25,
        },
        p=0.75,
    ),
    'mo1': tio.RandomMotion(p=0.1),
    'bi1': tio.RandomBiasField(coefficients=(0, 0.1), p=0.1),
    'no0': tio.RandomNoise(std=(0, 0.1), p=0.15),
    'bl0': tio.Compose(
        [
            tio.RandomBlur(std=(0.5, 1.5), p=0.5, include=['t1']),
            tio.RandomBlur(std=(0.5, 1.5), p=0.5, include=['t1ce']),
            tio.RandomBlur(std=(0.5, 1.5), p=0.5, include=['t2']),
            tio.RandomBlur(std=(0.5, 1.5), p=0.5, include=['flair']),
        ],
        p=0.2,
    ),
    'br0': tio.Lambda(partial(augment_brightness, multiplier_range=(0.7, 1.3)),
                      types_to_apply=[tio.INTENSITY], p=0.15),
    'co0': tio.Lambda(partial(augment_contrast, contrast_range=(0.65, 1.5)),
                      types_to_apply=[tio.INTENSITY], p=0.15),
    'an0': tio.Compose(
        [
            tio.RandomAnisotropy(downsampling=(1, 2), p=0.5, include=['t1']),
            tio.RandomAnisotropy(downsampling=(1, 2), p=0.5, include=['t1ce']),
            tio.RandomAnisotropy(downsampling=(1, 2), p=0.5, include=['t2']),
            tio.RandomAnisotropy(downsampling=(1, 2), p=0.5, include=['flair']),
        ],
        p=0.25,
    ),
    'gi0': tio.Lambda(partial(augment_gamma, gamma_range=(0.7, 1.5), invert_image=True),
                      types_to_apply=[tio.INTENSITY], p=0.15),
    'ga0': tio.Lambda(partial(augment_gamma, gamma_range=(0.7, 1.5), invert_image=False),
                      types_to_apply=[tio.INTENSITY], p=0.15),
    'fl0': tio.RandomFlip(axes=(0, 1, 2)),
    'fl1': tio.RandomFlip(),
}


def get_transform_aug(aug_seq='af0-no0-bl0-br0-co0-an0-gi0-ga0-fl0'):
    return [transform_augs[aug] for aug in aug_seq.split('-')]


def get_m_indexes(modalities=None):
    if modalities is None:
        modalities = ['T1', 'T1CE', 'T2', 'FLAIR']
    full_index = range(len(modalities))
    m_indexes = {}
    for r in range(1, len(full_index)):
        r_indexes = list(itertools.combinations(full_index, r))
        missing_indexes = [list(set(full_index) - set(r_index)) for r_index in r_indexes]
        for r_index, missing_index in zip(r_indexes, missing_indexes):
            remaining = ', '.join([modalities[r_ind] for r_ind in r_index])
            m_indexes[remaining] = missing_index
    return m_indexes


def plot_augmentations(subj, transform_aug, n_e=8, n_e_col=2, show=True, save=False, path=None):
    subj_aug = transform_aug(subj)
    modalities = list(subj_aug.keys())[:4]
    axial = subj_aug[modalities[0]]['data'].shape[3] // 2
    n, n_cols = n_e * 4, n_e_col * 4
    n_rows = int(np.ceil(n / n_cols))
    if show:
        # https://stackoverflow.com/a/56320309
        matplotlib.use('qt5agg')
    else:
        matplotlib.use('agg')
    fig, ax = plt.subplots(n_rows, n_cols, figsize=(n_cols * 2, n_rows * 2),
                           constrained_layout=True)
    for i, ax_i in enumerate(ax.ravel()):
        ax_i.axis('off')
        if i < n:
            if i % 4 == 0:
                subj_aug = transform_aug(subj)
            modality = modalities[i % 4]
            ax_i.imshow(subj_aug[modality]['data'][0, :, :, axial].T, cmap='gray', origin='lower')
            ax_i.set_title(f"Epoch {i // 4 + 1}: {modality.upper()}")
    if save and path is not None:
        plt.savefig(path, pad_inches=0)
    if show:
        plt.show()
    else:
        plt.close()


def zscore_train_test(train, test):
    mu_train = np.nanmean(train, axis=0)
    sigma_train = np.nanstd(train, axis=0, ddof=1)
    sigma_train[sigma_train == 0] = 1
    zscore_train = np.nan_to_num((train - mu_train) / sigma_train)
    zscore_test = np.nan_to_num((test - mu_train) / sigma_train)
    return zscore_train, zscore_test


# https://discuss.pytorch.org/t/how-to-replace-all-relu-activations-in-a-pretrained-network/31591/7
# https://stackoverflow.com/q/36901
# https://docs.python.org/3/tutorial/controlflow.html#more-on-defining-functions
def replace_module(net, type_old, type_new, *args, **kwargs):
    if isinstance(type_old, list):
        assert len(type_old) == 2
        type_old_, attrs = type_old
        assert isinstance(attrs, dict)
        for n, m in net.named_children():
            if isinstance(m, type_old_):
                matched = True
                for attr, value in attrs.items():
                    if getattr(m, attr) != value:
                        matched = False
                        break
                if matched:
                    setattr(net, n, type_new(*args, **kwargs))
            else:
                replace_module(m, type_old, type_new, *args, **kwargs)
    else:
        for n, m in net.named_children():
            if isinstance(m, type_old):
                setattr(net, n, type_new(*args, **kwargs))
            else:
                replace_module(m, type_old, type_new, *args, **kwargs)


def print_param(net, show_each=True):
    max_len_name = 0
    n_param = 0
    for name, param in net.named_parameters():
        if param.requires_grad:
            if show_each:
                if len(name) > max_len_name:
                    max_len_name = len(name)
            n_param += np.prod(param.shape)
    if show_each:
        for name, param in net.named_parameters():
            if param.requires_grad:
                print("{:{:d}s}    {:s}".format(name, max_len_name, str(param.shape)))
    print(f"Number of Parameters = {n_param}")


def plot_error_vs_epoch(errors, y_label, show=True, save=False, path='./error_vs_epoch.pdf'):
    cross_entropy_errors, styles, labels = zip(*errors)
    epoch = len(cross_entropy_errors[0])
    x = range(1, epoch + 1)
    if show:
        # https://stackoverflow.com/a/56320309
        matplotlib.use('qt5agg')
    else:
        matplotlib.use('agg')
    plt.figure(figsize=(8, 4))
    for i in range(len(cross_entropy_errors)):
        plt.plot(x, cross_entropy_errors[i], styles[i], label=labels[i])
    plt.legend()
    plt.xlim(0, epoch)
    if epoch <= 10:
        x_ticks = range(0, epoch + 1)
    else:
        x_ticks = range(0, epoch + 1, int(np.ceil(epoch / 10)))
    plt.xticks(x_ticks)
    plt.xlabel("Number of Epochs")
    plt.ylabel(y_label)
    plt.title(y_label + " vs Number of Epochs")
    if save:
        plt.savefig(path, pad_inches=0)
    if show:
        plt.show()
    else:
        plt.close()


class FocalLoss(nn.modules.loss._WeightedLoss):
    __constants__ = ['gamma', 'ignore_index', 'reduction']
    ignore_index: int

    def __init__(self, weight: Optional[torch.Tensor] = None, gamma: float = 2, size_average=None,
                 ignore_index: int = -100, reduce=None, reduction: str = 'mean') -> None:
        super(FocalLoss, self).__init__(weight, size_average, reduce, reduction)
        self.gamma = gamma
        self.ignore_index = ignore_index

    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        log_prob = F.log_softmax(input, dim=0 if input.dim() == 1 else 1)
        return F.nll_loss((1 - log_prob.exp()) ** self.gamma * log_prob, target, weight=self.weight,
                          ignore_index=self.ignore_index, reduction=self.reduction)


def cross_entropy(f_x, y):
    return log_loss(y, f_x)


def accuracy(f_x, y):
    return accuracy_score(y.argmax(1), f_x.argmax(1))


def balanced_accuracy(f_x, y):
    return balanced_accuracy_score(y.argmax(1), f_x.argmax(1))


def sensitivity(f_x, y):
    return recall_score(y.argmax(1), f_x.argmax(1), pos_label=1)


def specificity(f_x, y):
    return recall_score(y.argmax(1), f_x.argmax(1), pos_label=0)


def auroc(f_x, y):
    return roc_auc_score(y, f_x)


def auprc(f_x, y):
    return average_precision_score(y, f_x)


def f_splits(splits, f_metric, f_x, y):
    indexes = np.unique(splits)
    metrics = np.zeros(indexes.shape)
    for i, index in enumerate(indexes):
        metrics[i] = f_metric(f_x[splits == index], y[splits == index])
    return metrics


# Location coherence
def lc(prob, seg, annos=None, threshold=None, topk_v=None, metric='AP'):
    lc_is = []
    for prob_i, seg_i in zip(prob, seg):
        lc_ijs = []
        anno = torch.zeros_like(seg_i[0])
        if isinstance(annos, list):
            for a in annos:
                anno[seg_i[0] == a] = 1
        else:
            anno[seg_i[0] > 0] = 1
        if threshold is None:
            if topk_v:
                quantile = 1 - topk_v / 100
            else:
                quantile = 1 - anno.sum() / anno.numel()
            threshold = torch.quantile(prob_i, quantile)
        else:
            prob_i = prob_i - prob_i.min()
            prob_i = prob_i / prob_i.max().clamp_min(1e-12)
        for prob_ij in prob_i:
            attr = torch.ones_like(prob_ij)
            attr[prob_ij < threshold] = 0
            if metric == 'AP':
                lc_ijs.append((anno * attr).sum() / attr.sum().clamp_min(1))
            elif metric == 'DSC':
                lc_ijs.append(2 * (anno * attr).sum() / (anno.sum() + attr.sum()).clamp_min(1))
            elif metric == 'IoU':
                lc_ijs.append((anno * attr).sum() / torch.logical_or(anno, attr).sum().clamp_min(1))
        lc_is.append(torch.hstack(lc_ijs))
    return torch.vstack(lc_is).cpu().numpy()


# Incremental addition/deletion
def iad(net, data, attr, n_intervals=100, uniform=True, quantile=True, addition=True):
    iads = []
    quantiles = torch.linspace(1, 0, n_intervals + 1).to(attr.device)
    if uniform:
        attr = attr.mean(1, keepdim=True)
    if quantile:
        thresholds = torch.quantile(attr.flatten(1), quantiles, dim=1)
    else:
        attr = attr - attr.amin(tuple(range(1, attr.ndim)), keepdim=True)
        attr = attr / attr.amax(tuple(range(1, attr.ndim)), keepdim=True).clamp_min(1e-12)
        thresholds = quantiles[:, None].tile(1, attr.shape[0])
    for i, threshold in enumerate(thresholds):
        if addition:
            mask = torch.zeros_like(attr)
            if i > 0:
                mask[attr >= threshold[(...,) + (None,) * (attr.ndim - 1)]] = 1
        else:
            mask = torch.ones_like(attr)
            if i > 0:
                mask[attr >= threshold[(...,) + (None,) * (attr.ndim - 1)]] = 0
        with torch.no_grad():
            iads.append(F.softmax(net(data * mask), dim=1))
    return torch.stack(iads).cpu().numpy()


def plot_iad(curve, ratio, method, metric, x_label, y_label, show=True, save=False, path=None):
    metric = {'IA': "Incremental Addition", 'ID': "Incremental Deletion"}[metric]
    x0 = np.linspace(0, 100, curve.shape[0])
    x = np.linspace(0, 100, (curve.shape[0] - 1) * 10 + 1)
    curve = np.interp(x, x0, curve)
    bounds = sorted([(curve[0], 'Start'), (curve[-1], 'End')])
    if show:
        # https://stackoverflow.com/a/56320309
        matplotlib.use('qt5agg')
    else:
        matplotlib.use('agg')
    plt.figure(figsize=(6, 4))
    h_c, = plt.plot(x, curve, label=metric)
    h_r = plt.fill_between(x, curve.clip(bounds[0][0], bounds[1][0]), bounds[0][0],
                           where=curve > bounds[0][0], color='dodgerblue', alpha=0.3,
                           label=f"Score: {ratio:.3f}")
    h_l = plt.axhline(bounds[0][0], color='r', alpha=0.7, linestyle=':',
                      label=f"Lower Bound ({bounds[0][1]})")
    h_u = plt.axhline(bounds[1][0], color='r', alpha=0.7, linestyle=(0, (2, 3)),
                      label=f"Upper Bound ({bounds[1][1]})")
    plt.legend(handles=[h_c, h_u, h_r, h_l])
    plt.xlim(0, 100)
    plt.xticks(np.arange(0, 110, 10))
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    if path[-3:] != 'pdf':
        plt.title(f"{method}: {metric} ({y_label})")
    if save and path is not None:
        plt.savefig(path, dpi=300, pad_inches=0)
        # print(f"Output {path}")
    if show:
        plt.show()
    else:
        plt.close()


def process_iad(iads, y, save_plot=True, model_name=None):
    for method, iads_ in iads.items():
        for metric, iads__ in iads_.items():
            if metric == 'IAD':
                continue
            curves = np.zeros((iads__.shape[0], 2))
            for i in range(iads__.shape[0]):
                curves[i, 0] = accuracy(iads__[i], y)
                curves[i, 1] = balanced_accuracy(iads__[i], y)
            ratios = curves.clip(curves[[0, -1], :].min(0), curves[[0, -1], :].max(0))
            ratios = ratios - ratios.min(0)
            ratios = ratios / ratios.max(0).clip(1e-12)
            iads[method][metric] = ((ratios[:-1] + ratios[1:]) / 2).mean(0, keepdims=True)
            if save_plot and model_name is not None:
                iads_dir = f'../results/iads/{model_name}/'
                makedir(iads_dir)
                plot_iad(curves[:, 0], iads[method][metric][0, 0], method, metric, "Top Voxels (%)",
                         "Accuracy", show=False, save=True,
                         path=f'{iads_dir}{method}_{metric}_ACC.pdf')
                plot_iad(curves[:, 0], iads[method][metric][0, 0], method, metric, "Top Voxels (%)",
                         "Accuracy", show=False, save=True,
                         path=f'{iads_dir}{method}_{metric}_ACC.png')
                plot_iad(curves[:, 1], iads[method][metric][0, 1], method, metric, "Top Voxels (%)",
                         "Balanced Accuracy", show=False, save=True,
                         path=f'{iads_dir}{method}_{metric}_BAC.pdf')
                plot_iad(curves[:, 1], iads[method][metric][0, 1], method, metric, "Top Voxels (%)",
                         "Balanced Accuracy", show=False, save=True,
                         path=f'{iads_dir}{method}_{metric}_BAC.png')
        if 'IAD' in iads_:
            iads[method]['IAD'] = (iads[method]['IA'] + (1 - iads[method]['ID'])) / 2


def print_results(dataset, f_x, y, m_f_xes=None, lcs=None, n_prototypes=None, iads=None,
                  splits=None):
    print(f"{dataset}", end='', flush=True)
    if splits is not None:
        accs = f_splits(splits, accuracy, f_x, y)
        bacs = f_splits(splits, balanced_accuracy, f_x, y)
        sens = f_splits(splits, sensitivity, f_x, y)
        spes = f_splits(splits, specificity, f_x, y)
        aucs = f_splits(splits, auroc, f_x, y)
        print(f" ACC: {accs.mean():.3f}±{accs.std():.3f},"
              f" BAC: {bacs.mean():.3f}±{bacs.std():.3f},"
              f" SEN: {sens.mean():.3f}±{sens.std():.3f},"
              f" SPE: {spes.mean():.3f}±{spes.std():.3f},"
              f" AUC: {aucs.mean():.3f}±{aucs.std():.3f}")
    else:
        print(f" ACC: {accuracy(f_x, y):.3f},"
              f" BAC: {balanced_accuracy(f_x, y):.3f},"
              f" SEN: {sensitivity(f_x, y):.3f},"
              f" SPE: {specificity(f_x, y):.3f},"
              f" AUC: {auroc(f_x, y):.3f}")
    if m_f_xes:
        maxlen_remaining = 0
        for remaining in m_f_xes:
            maxlen_remaining = max(len(remaining), maxlen_remaining)
        for remaining, m_f_x in m_f_xes.items():
            print(f"({remaining:>{maxlen_remaining}})", end='', flush=True)
            if splits is not None:
                accs = f_splits(splits, accuracy, m_f_x, y)
                bacs = f_splits(splits, balanced_accuracy, m_f_x, y)
                sens = f_splits(splits, sensitivity, m_f_x, y)
                spes = f_splits(splits, specificity, m_f_x, y)
                aucs = f_splits(splits, auroc, m_f_x, y)
                print(f" ACC: {accs.mean():.3f}±{accs.std():.3f},"
                      f" BAC: {bacs.mean():.3f}±{bacs.std():.3f},"
                      f" SEN: {sens.mean():.3f}±{sens.std():.3f},"
                      f" SPE: {spes.mean():.3f}±{spes.std():.3f},"
                      f" AUC: {aucs.mean():.3f}±{aucs.std():.3f}")
            else:
                print(f" ACC: {accuracy(m_f_x, y):.3f},"
                      f" BAC: {balanced_accuracy(m_f_x, y):.3f},"
                      f" SEN: {sensitivity(m_f_x, y):.3f},"
                      f" SPE: {specificity(m_f_x, y):.3f},"
                      f" AUC: {auroc(m_f_x, y):.3f}")
    if lcs:
        maxlen_method, maxlen_metric = 0, 0
        for method, lcs_ in lcs.items():
            for metric, lcs__ in lcs_.items():
                maxlen_method = max(len(method), maxlen_method)
                maxlen_metric = max(len(metric), maxlen_metric)
        for method, lcs_ in lcs.items():
            for metric, lcs__ in lcs_.items():
                print(f"{method:>{maxlen_method}} {metric:<{maxlen_metric}}:"
                      f" {lcs__.mean(1).mean():.3f}±{lcs__.mean(1).std():.3f}"
                      f" (T1: {lcs__[:, 0].mean():.3f}±{lcs__[:, 0].std():.3f},"
                      f" T1CE: {lcs__[:, 1].mean():.3f}±{lcs__[:, 1].std():.3f},"
                      f" T2: {lcs__[:, 2].mean():.3f}±{lcs__[:, 2].std():.3f},"
                      f" FLAIR: {lcs__[:, 3].mean():.3f}±{lcs__[:, 3].std():.3f})")
    if n_prototypes is not None:
        for n_prototype in n_prototypes:
            print(f"        No. of Prototypes\t"
                  f" All: {n_prototype.sum():.0f},"
                  f" HGG: {n_prototype[1]:.0f},"
                  f" LGG: {n_prototype[0]:.0f}")
        if len(n_prototypes) > 1:
            print(f"Average No. of Prototypes\t"
                  f" All: {n_prototypes.sum(1).mean():.1f}±{n_prototypes.sum(1).std():.1f},"
                  f" HGG: {n_prototypes[:, 1].mean():.1f}±{n_prototypes[:, 1].std():.1f},"
                  f" LGG: {n_prototypes[:, 0].mean():.1f}±{n_prototypes[:, 0].std():.1f}")
    if iads:
        maxlen_method, maxlen_metric = 0, 0
        for method, iads_ in iads.items():
            for metric, iads__ in iads_.items():
                maxlen_method = max(len(method), maxlen_method)
                maxlen_metric = max(len(metric), maxlen_metric)
        for method, iads_ in iads.items():
            for metric, iads__ in iads_.items():
                print(f"{method:>{maxlen_method}} {metric:<{maxlen_metric}}:"
                      f" {iads__[:, 0].mean():.3f}±{iads__[:, 0].std():.3f} (ACC),"
                      f" {iads__[:, 1].mean():.3f}±{iads__[:, 1].std():.3f} (BAC)")


def output_results(dataset, args, batch_size, f_x, y, m_f_xes=None, lcs=None, n_prototypes=None,
                   iads=None, splits=None, file='../results/raw.md'):
    hostname = socket.gethostname()
    # https://stackoverflow.com/a/28950776
    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
        s.settimeout(0)
        s.connect(('10.254.254.254', 1))
        ip = s.getsockname()[0]
    cur_time = time.strftime('%Y/%m/%d %H:%M:%S %z')
    opts_hash = get_hashes(args)
    with open(file, 'a', encoding='utf-8', newline='\n') as f:
        f.write(f"# {hostname} ({ip}): {cur_time}\n\n")
        f.write(f"```python\n{args}\n```\n\n")
        f.write(f"## Results: {dataset}\n\n")
        f.write("|Model|BS|ACC|BAC|SEN|SPE|AUC|\n")
        f.write("|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n")
        f.write(f"|{args.model_name}_{opts_hash}|{batch_size}|")
        if splits is not None:
            accs = f_splits(splits, accuracy, f_x, y)
            bacs = f_splits(splits, balanced_accuracy, f_x, y)
            sens = f_splits(splits, sensitivity, f_x, y)
            spes = f_splits(splits, specificity, f_x, y)
            aucs = f_splits(splits, auroc, f_x, y)
            f.write(f"{accs.mean():.3f}±{accs.std():.3f}|"
                    f"{bacs.mean():.3f}±{bacs.std():.3f}|"
                    f"{sens.mean():.3f}±{sens.std():.3f}|"
                    f"{spes.mean():.3f}±{spes.std():.3f}|"
                    f"{aucs.mean():.3f}±{aucs.std():.3f}|\n\n")
        else:
            f.write(f"{accuracy(f_x, y):.3f}|"
                    f"{balanced_accuracy(f_x, y):.3f}|"
                    f"{sensitivity(f_x, y):.3f}|"
                    f"{specificity(f_x, y):.3f}|"
                    f"{auroc(f_x, y):.3f}|\n\n")
        if m_f_xes:
            f.write("|Modalities|ACC|BAC|SEN|SPE|AUC|\n")
            f.write("|:-:|:-:|:-:|:-:|:-:|:-:|\n")
            for remaining, m_f_x in m_f_xes.items():
                f.write(f"|{remaining}|")
                if splits is not None:
                    accs = f_splits(splits, accuracy, m_f_x, y)
                    bacs = f_splits(splits, balanced_accuracy, m_f_x, y)
                    sens = f_splits(splits, sensitivity, m_f_x, y)
                    spes = f_splits(splits, specificity, m_f_x, y)
                    aucs = f_splits(splits, auroc, m_f_x, y)
                    f.write(f"{accs.mean():.3f}±{accs.std():.3f}|"
                            f"{bacs.mean():.3f}±{bacs.std():.3f}|"
                            f"{sens.mean():.3f}±{sens.std():.3f}|"
                            f"{spes.mean():.3f}±{spes.std():.3f}|"
                            f"{aucs.mean():.3f}±{aucs.std():.3f}|\n")
                else:
                    f.write(f"{accuracy(m_f_x, y):.3f}|"
                            f"{balanced_accuracy(m_f_x, y):.3f}|"
                            f"{sensitivity(m_f_x, y):.3f}|"
                            f"{specificity(m_f_x, y):.3f}|"
                            f"{auroc(m_f_x, y):.3f}|\n")
            f.write('\n')
        if lcs:
            f.write(f"|Method|Metric|Average|T1|T1CE|T2|FLAIR|\n")
            f.write("|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n")
            for method, lcs_ in lcs.items():
                for metric, lcs__ in lcs_.items():
                    f.write(f"|{method}|{metric}|"
                            f"{lcs__.mean(1).mean():.3f}±{lcs__.mean(1).std():.3f}|"
                            f"{lcs__[:, 0].mean():.3f}±{lcs__[:, 0].std():.3f}|"
                            f"{lcs__[:, 1].mean():.3f}±{lcs__[:, 1].std():.3f}|"
                            f"{lcs__[:, 2].mean():.3f}±{lcs__[:, 2].std():.3f}|"
                            f"{lcs__[:, 3].mean():.3f}±{lcs__[:, 3].std():.3f}|\n")
            f.write('\n')
        if n_prototypes is not None:
            f.write(f"|CV|All|HGG|LGG|\n")
            f.write("|:-:|:-:|:-:|:-:|\n")
            for cv, n_prototype in enumerate(n_prototypes):
                f.write(f"|{cv + 1}|"
                        f"{n_prototype.sum():.0f}|"
                        f"{n_prototype[1]:.0f}|"
                        f"{n_prototype[0]:.0f}|\n")
            f.write(f"|Average|"
                    f"{n_prototypes.sum(1).mean():.1f}±{n_prototypes.sum(1).std():.1f}|"
                    f"{n_prototypes[:, 1].mean():.1f}±{n_prototypes[:, 1].std():.1f}|"
                    f"{n_prototypes[:, 0].mean():.1f}±{n_prototypes[:, 0].std():.1f}|\n")
            f.write('\n')
        if iads:
            f.write(f"|Method|Metric|ACC|BAC|\n")
            f.write("|:-:|:-:|:-:|:-:|\n")
            for method, iads_ in iads.items():
                for metric, iads__ in iads_.items():
                    f.write(f"|{method}|{metric}|"
                            f"{iads__[:, 0].mean():.3f}±{iads__[:, 0].std():.3f}|"
                            f"{iads__[:, 1].mean():.3f}±{iads__[:, 1].std():.3f}|\n")
            f.write('\n')


def save_cvs(cv_dir, args, f_x, y, lcs, iads, splits):
    opts_hash = get_hashes(args)
    file = f'{cv_dir}{args.model_name}_{opts_hash}.joblib'
    bacs = f_splits(splits, balanced_accuracy, f_x, y)
    aucs = f_splits(splits, auroc, f_x, y)
    method = 'MProtoNet' if lcs.get('MProtoNet') else 'GradCAM'
    aps = lcs[method]['(WT, Th=0.5) AP'].mean(1)
    dscs = lcs[method]['(WT, Th=0.5) DSC'].mean(1)
    method = 'MProtoNet' if iads.get('MProtoNet') else 'GradCAM'
    ias = iads[method]['IA'][:, 1]
    ids = iads[method]['ID'][:, 1]
    cvs = {'bacs': bacs, 'aucs': aucs, 'aps': aps, 'dscs': dscs, 'ias': ias, 'ids': ids}
    joblib.dump(cvs, file, compress=True)
